{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill - Threading\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Exercise 1\n",
    "In the `data/` folder, you have 10 files that contain Shakespears sonnets. You have to gather all these files into one file `data_all.txt` using threads. Be careful, the sonnets must appear in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_files_name():\n",
    "    # get the list of text files in the directory\n",
    "    path_of_the_directory = 'data'\n",
    "    filename_list = []\n",
    "    ext = ('.txt')\n",
    "    for file in os.listdir(path_of_the_directory):\n",
    "        if file.endswith(ext) & (file != 'data_all.txt')&(file !='data_part_10.txt'):\n",
    "            filename_list.append(file) \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    filename_list.append('data_part_10.txt')\n",
    "    return filename_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_files(dir):\n",
    "    # write the content of the files into data_all.txt file\n",
    "   \n",
    "    print(f\"Task {dir}: starting. \")\n",
    "\n",
    "    with open('data/data_all.txt', 'a') as af:\n",
    "        with open(dir,'r') as rf:\n",
    "            af.write(rf.read())\n",
    "    print(f\"Task {dir}: finished. \")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task data/data_part_1.txt: starting. \n",
      "Task data/data_part_1.txt: finished. \n",
      "Task data/data_part_2.txt: starting. \n",
      "Task data/data_part_2.txt: finished. \n",
      "Task data/data_part_3.txt: starting. \n",
      "Task data/data_part_3.txt: finished. \n",
      "Task data/data_part_4.txt: starting. \n",
      "Task data/data_part_4.txt: finished. \n",
      "Task data/data_part_5.txt: starting. \n",
      "Task data/data_part_5.txt: finished. \n",
      "Task data/data_part_6.txt: starting. \n",
      "Task data/data_part_6.txt: finished. \n",
      "Task data/data_part_7.txt: starting. \n",
      "Task data/data_part_7.txt: finished. \n",
      "Task data/data_part_8.txt: starting. \n",
      "Task data/data_part_8.txt: finished. \n",
      "Task data/data_part_9.txt: starting. \n",
      "Task data/data_part_9.txt: finished. \n",
      "Task data/data_part_10.txt: starting. \n",
      "Task data/data_part_10.txt: finished. \n",
      "\n",
      "Time spent inside the loop: 0.007544499938376248 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 1. with out concurrency\n",
    "from time import perf_counter\n",
    "\n",
    "with open(\"data/data_all.txt\",'w') as wf:# first delete the file incase there is some text already\n",
    "        pass\n",
    "\n",
    "start_time = perf_counter()\n",
    "filename_list = get_files_name()\n",
    "for filename in filename_list:\n",
    "    dir = 'data/' + filename\n",
    "    write_files(dir)\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task data/data_part_1.txt: starting. \n",
      "Task data/data_part_2.txt: starting. \n",
      "Task data/data_part_3.txt: starting. \n",
      "Task data/data_part_4.txt: starting. \n",
      "Task data/data_part_5.txt: starting. \n",
      "Task data/data_part_6.txt: starting. \n",
      "Task data/data_part_1.txt: finished. \n",
      "Task data/data_part_3.txt: finished. \n",
      "Task data/data_part_2.txt: finished. \n",
      "Task data/data_part_7.txt: starting. \n",
      "Task data/data_part_4.txt: finished. \n",
      "Task data/data_part_5.txt: finished. \n",
      "Task data/data_part_6.txt: finished. \n",
      "Task data/data_part_8.txt: starting. \n",
      "Task data/data_part_9.txt: starting. \n",
      "Task data/data_part_7.txt: finished. \n",
      "Task data/data_part_10.txt: starting. \n",
      "Task data/data_part_8.txt: finished. \n",
      "Task data/data_part_10.txt: finished. \n",
      "Task data/data_part_9.txt: finished. \n",
      "\n",
      "Time spent inside the loop: 0.008241200004704297 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 2. using threading\n",
    "from threading import Thread\n",
    "threads = list()\n",
    "start_time = perf_counter()\n",
    "\n",
    "with open(\"data/data_all.txt\",'w') as wf:# first delete the file incase there is some text already\n",
    "        pass\n",
    "\n",
    "for filename in filename_list:\n",
    "    dir = 'data/' + filename\n",
    "    thread = Thread(target = write_files, args =(dir,)) # new thread will run \"write_files\" with argument \"dir\"\n",
    "    threads.append(thread)# to keep track of all the treads\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join() # Make sure all the threads are done before continuing\n",
    "\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 locked concurrency\n",
    "\n",
    "from threading import RLock\n",
    "rlock = RLock() # Needs to be outside the function. Created once, used by every thread.\n",
    "\n",
    "def write_file_locked(dir):\n",
    "    with rlock:\n",
    "        print(f\"Task {dir}: starting. \")\n",
    "    with open('data/data_all.txt', 'a') as af:\n",
    "        with open(dir,'r') as rf:\n",
    "            af.write(rf.read())\n",
    "    with rlock:\n",
    "        print(f\"Task {dir}: finishing. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task data/data_part_1.txt: starting. \n",
      "Task data/data_part_2.txt: starting. \n",
      "Task data/data_part_3.txt: starting. \n",
      "Task data/data_part_4.txt: starting. \n",
      "Task data/data_part_5.txt: starting. \n",
      "Task data/data_part_6.txt: starting. \n",
      "Task data/data_part_1.txt: finishing. \n",
      "Task data/data_part_7.txt: starting. \n",
      "Task data/data_part_8.txt: starting. \n",
      "Task data/data_part_2.txt: finishing. \n",
      "Task data/data_part_3.txt: finishing. \n",
      "Task data/data_part_4.txt: finishing. \n",
      "Task data/data_part_9.txt: starting. \n",
      "Task data/data_part_5.txt: finishing. \n",
      "Task data/data_part_10.txt: starting. \n",
      "Task data/data_part_7.txt: finishing. \n",
      "Task data/data_part_6.txt: finishing. \n",
      "Task data/data_part_8.txt: finishing. \n",
      "Task data/data_part_10.txt: finishing. \n",
      "Task data/data_part_9.txt: finishing. \n",
      "\n",
      "Time spent inside the loop: 0.03057870001066476 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "with open(\"data/data_all.txt\",'w') as wf:# first delete the file incase there is some text already\n",
    "        pass\n",
    "\n",
    "threads = list()\n",
    "for filename in filename_list:\n",
    "    dir = \"data/\" + filename\n",
    "    thread = Thread(target=write_file_locked, args=(dir,))\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores on my machine: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "print(f\"Number of CPU cores on my machine: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadata_part_1.txt\n",
      "/datadata_part_2.txt\n",
      "/datadata_part_3.txt\n",
      "/datadata_part_4.txt\n",
      "/datadata_part_5.txt\n",
      "/datadata_part_6.txt\n",
      "/datadata_part_7.txt\n",
      "/datadata_part_8.txt\n",
      "/datadata_part_9.txt\n",
      "/datadata_part_10.txt\n",
      "\n",
      "Time spent inside the loop: 0.19446020002942532 seconds.\n"
     ]
    }
   ],
   "source": [
    "#4 using multiprocess\n",
    "from multiprocessing import Process\n",
    "\n",
    "start_time = perf_counter()\n",
    "processes = list()\n",
    "\n",
    "with open(\"data/data_all.txt\",'w') as wf:# first delete the file incase there is some text already\n",
    "        pass\n",
    "\n",
    "for filename in filename_list:\n",
    "    dir = \"/data\" + filename\n",
    "    print(dir)\n",
    "    process = Process(target= write_files, args=(dir,))\n",
    "    processes.append(process)\n",
    "\n",
    "for process in processes:\n",
    "    process.start()\n",
    "\n",
    "for process in processes:\n",
    "    process.join()\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map workers and pools\n",
    "#They are high-level tools to help you inject concurrency and parallelism into your code less painfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/data_part_1.txt', 'data/data_part_2.txt', 'data/data_part_3.txt', 'data/data_part_4.txt', 'data/data_part_5.txt', 'data/data_part_6.txt', 'data/data_part_7.txt', 'data/data_part_8.txt', 'data/data_part_9.txt', 'data/data_part_10.txt']\n",
      "Task data/data_part_1.txt: starting. \n",
      "Task data/data_part_1.txt: finished. \n",
      "Task data/data_part_2.txt: starting. \n",
      "Task data/data_part_2.txt: finished. \n",
      "Task data/data_part_3.txt: starting. \n",
      "Task data/data_part_3.txt: finished. \n",
      "Task data/data_part_4.txt: starting. \n",
      "Task data/data_part_4.txt: finished. \n",
      "Task data/data_part_5.txt: starting. \n",
      "Task data/data_part_5.txt: finished. \n",
      "Task data/data_part_6.txt: starting. \n",
      "Task data/data_part_6.txt: finished. \n",
      "Task data/data_part_7.txt: starting. \n",
      "Task data/data_part_7.txt: finished. \n",
      "Task data/data_part_8.txt: starting. \n",
      "Task data/data_part_8.txt: finished. \n",
      "Task data/data_part_9.txt: starting. \n",
      "Task data/data_part_9.txt: finished. \n",
      "Task data/data_part_10.txt: starting. \n",
      "Task data/data_part_10.txt: finished. \n",
      "\n",
      "Time spent inside the loop: 0.006264699972234666 seconds.\n"
     ]
    }
   ],
   "source": [
    "arguments = []\n",
    "for fname in filename_list:\n",
    "    arguments.append('data/'+ fname)\n",
    "print(arguments)\n",
    "\n",
    "start_time = perf_counter()\n",
    "gen = map(write_files, arguments) # map is a generator (think yield)\n",
    "tuple(gen) # do the actual work\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task data/data_part_1.txt: starting. \n",
      "Task data/data_part_2.txt: starting. \n",
      "Task data/data_part_3.txt: starting. \n",
      "Task data/data_part_4.txt: starting. \n",
      "Task data/data_part_2.txt: finished. \n",
      "Task data/data_part_5.txt: starting. \n",
      "Task data/data_part_1.txt: finished. \n",
      "Task data/data_part_6.txt: starting. \n",
      "Task data/data_part_7.txt: starting. \n",
      "Task data/data_part_8.txt: starting. \n",
      "Task data/data_part_3.txt: finished. \n",
      "Task data/data_part_9.txt: starting. \n",
      "Task data/data_part_10.txt: starting. \n",
      "Task data/data_part_4.txt: finished. \n",
      "Task data/data_part_5.txt: finished. \n",
      "Task data/data_part_7.txt: finished. \n",
      "Task data/data_part_8.txt: finished. \n",
      "Task data/data_part_9.txt: finished. \n",
      "Task data/data_part_6.txt: finished. \n",
      "Task data/data_part_10.txt: finished. \n",
      "\n",
      "Time spent inside the loop: 0.009367499966174364 seconds.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor() as pool: # Without arguments, ThreadPoolExecutor() will create as many workers as CPU cores + 4\n",
    "    tuple(pool.map(write_files, arguments))\n",
    "\n",
    "print(f\"\\nTime spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "start_time = perf_counter()\n",
    "nb_workers = 8\n",
    "\n",
    "with Pool(processes = nb_workers) as pool: # We fix the number of workers ourselve\n",
    "     tuple(pool.map(write_files, arguments))\n",
    "print(f\"[{nb_workers} workers] Time spent inside the loop: {perf_counter() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Scrap all the web pages in the `urls` list and display the links. 1 thread per link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"http://www.python.org\",\n",
    "    \"http://www.python.org/about/\",\n",
    "    \"http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html\",\n",
    "    \"http://www.python.org/doc/\",\n",
    "    \"http://www.python.org/download/\",\n",
    "    \"http://www.python.org/getit/\",\n",
    "    \"http://www.python.org/community/\",\n",
    "    \"https://wiki.python.org/moin/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.10.0 ('real_estate_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "aed70a1e44534e5788bf30bd732a6f043afa88f39bad6148082b12cca697aba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
